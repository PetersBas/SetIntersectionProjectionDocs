<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="generator" content="scholpandoc">
  <meta name="viewport" content="width=device-width">
  
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.7.1/modernizr.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.js"></script>
  <link rel="stylesheet" href="https://www.slim.eos.ubc.ca/Publications/Resources/ScholMD/standalone/slimweb-scholmd-standalone-v0.1-latest.min.css">
</head>
<body>
<div class="scholmd-container">
<div class="scholmd-main">
<div class="math scholmd-math-definitions" style="visibility: hidden; height: 0px; width 0px;">\[
\def\bb{\mathbf b}
\def\bc{\mathbf c}
\def\bd{\mathbf d}
\def\bg{\mathbf g}
\def\bh{\mathbf h}
\def\bl{\mathbf l}
\def\bm{\mathbf m}
\def\bp{\mathbf p}
\def\bq{\mathbf q}
\def\br{\mathbf r}
\def\bs{\mathbf s}
\def\bu{\mathbf u}
\def\bv{\mathbf v}
\def\bw{\mathbf w}
\def\by{\mathbf y}
\def\bx{\mathbf x}
\def\bz{\mathbf z}
%\def\argmin{\operatornamewithlimits{arg min}}
\def\argmin{\mathop{\rm arg\min}}
\]</div>
<div class="scholmd-content">
<h1 id="image-processing-by-learning-a-parametric-intersection-of-non-convex-sets">Image processing by learning a parametric intersection of (non-)convex sets</h1>
<p><a href="../examples/Ecuador_deblurring_inpainting/deblurring_inpainting_by_constraint_learning_SA.jl">Julia script for this example a) (joint image denoising+deblurring+inpainting)</a></p>
<p><a href="../examples/Indonesia_deblurring/image_desaturation_by_constraint_learning.jl">Julia script for this example b) (image desaturation)</a></p>
<p>The applications of interest for this example are linear inverse problems, such as removing motion blur with a known blurring kernel and inpainting of missing pixels, single-image super-resolution, denoising, and desaturation of saturated images. We use aerial photos as the target. We can solve these various image processing tasks with the following simple strategy:</p>
<ol type="1">
<li>Observe (learn) the parameters of various constraint sets in various transform-domains by looking at just a few representative training images.</li>
<li>Add a constraint set for data-fit</li>
<li>Project a noisy/saturated/blurred/masked image onto the intersection of the learned (model properties) sets and data-fit set.</li>
<li>The projection of the corrupted image should now have similar properties as good training images.</li>
</ol>
<p>We formulate the projection problem as 
<span class="math scholmd-math-display" style="display: block;">\[
\begin{equation}
\min_{\bx,\by_i} \frac{1}{2}\| \bx - \bm \|_2^2 + \sum_{i=1}^{p-1} \iota_{\mathcal{C}_i}(\by_i) + \iota_{\mathcal{C}_p^\text{data}}(\by_p)\quad \text{s.t.} \quad \begin{cases}
A_i \bx = \by_i \\ B\bx=\by_p
\end{cases}
\label{proj_intersect_lininvprob2}
\end{equation}
\]</span>
 and solve it with the PARSDMM algortihm. This is a linear inverse problem with forward/observation operator, <span class="math scholmd-math-inline">\(B \in \mathbb{R}^{M \times N}\)</span>, model estimation <span class="math scholmd-math-inline">\(\bx \in \mathbb{R}^N\)</span> and the observed data <span class="math scholmd-math-inline">\(\bd_\text{obs} \in \mathbb{R}^M\)</span>. The solution is the projection of the initial guess <span class="math scholmd-math-inline">\(\bm\)</span> onto the intersection of constraint sets that describe the model <span class="math scholmd-math-inline">\(\bx\)</span> and a data constraint set <span class="math scholmd-math-inline">\(\mathcal{C}_p^{\text{data}}\)</span>. Examples of data-fit constraints are <span class="math scholmd-math-inline">\(\{ \bx \: | \: \bl \leq (B \bx - \bd_\text{obs}) \leq \bu\}\)</span> and <span class="math scholmd-math-inline">\(\{ \bx \: | \: \| B \bx - \bd_\text{obs} \|_2 \leq \sigma \}\)</span>.</p>
<p>For both examples we observe the following constraint parameters:</p>
<ol type="1">
<li>upper and lower bounds: <span class="math scholmd-math-inline">\(\{ \bm \: | \: \bl_i \leq \bm_i \leq \bu_i \}\)</span></li>
<li>nuclear norm: <span class="math scholmd-math-inline">\(\{ \bm \: | \: \sum_{j=1}^k \lambda_j \leq \sigma \}\)</span>, with <span class="math scholmd-math-inline">\(\bm = \textbf{vec}( \sum_{j=1}^{k}\lambda_j \bu_j \bv_j^* )\)</span> is the SVD of the image</li>
<li>nuclear norm of discrete gradients of the image (total-nuclear-variation): <span class="math scholmd-math-inline">\(\{ \bm \: | \: \sum_{j=1}^k \lambda_j \leq \sigma \}\)</span>, with <span class="math scholmd-math-inline">\((I_{n_x} \otimes D_z)\bm = \textbf{vec}( \sum_{j=1}^{k}\lambda_j \bu_j \bv_j^* )\)</span> is the SVD of the vertical derivative of the image, same for the other direction</li>
<li>anisotropic total-variation: <span class="math scholmd-math-inline">\(\{ \bm \: | \: \| A \bm \|_1 \leq \sigma \}\)</span> with <span class="math scholmd-math-inline">\(A = ((I_{n_x} \otimes D_z)^T \: (D_x \otimes I_{n_z})^T)^T\)</span></li>
<li>annulus: <span class="math scholmd-math-inline">\(\{ \bm \: | \: \sigma_l \leq \| \bm \|_2 \leq \sigma_u \}\)</span></li>
<li>annulus of the discrete gradients of the training images: <span class="math scholmd-math-inline">\(\{ \bm \: | \: \sigma_l \leq \| A \bm \|_2 \leq \sigma_u \}\)</span> with <span class="math scholmd-math-inline">\(A = ((I_{n_x} \otimes D_z)^T \: (D_x \otimes I_{n_z})^T)^T\)</span></li>
<li><span class="math scholmd-math-inline">\(\ell_1\)</span>-norm of DFT coefficients: <span class="math scholmd-math-inline">\(\{ \bm \: | \: \| A \bm \|_1 \leq \sigma \}\)</span> with <span class="math scholmd-math-inline">\(A = \)</span> discrete Fourier transform</li>
<li>slope-constraints in x and z direction (bounds on the discrete gradients of the image): <span class="math scholmd-math-inline">\(\{ \bm \: | \: \bl_i \leq (D_x \otimes I_{n_z}) \bm)_i \leq \bu_i \}\)</span> with all <span class="math scholmd-math-inline">\(\bu_i = \varepsilon_u\)</span> and <span class="math scholmd-math-inline">\(\bl_i = - \varepsilon_l\)</span>, same for z-direction</li>
<li>point-wise bound-constraints on DCT coefficients: <span class="math scholmd-math-inline">\(\{ \bm \: | \: \bl_i \leq (A \bm)_i \leq \bu_i \}\)</span>, with <span class="math scholmd-math-inline">\(A=\)</span> discrete cosine transform</li>
</ol>
<p>We also add a point-wise data-fit constraint, <span class="math scholmd-math-inline">\(\{ \bx \: | \: \bl \leq (B \bx - \bd_\text{obs}) \leq \bu\}\)</span>.</p>
<h2 id="example-1-joint-denoising-deblurring-inpainting">Example 1: joint denoising-deblurring-inpainting</h2>
<p>The goal of the first example is to recover an image from <span class="math scholmd-math-inline">\(20\%\)</span> observed pixels of a blurred image (25 pixels known motion blur), where each observed data-point also contains a small amount of random noise in the interval <span class="math scholmd-math-inline">\([-2 - 2]\)</span>. The dataset is a series of images from ‘Planet Labs PlanetScope Ecuador’ with a resolution of three meters, available at openaerialmap.org. There are <span class="math scholmd-math-inline">\(35\)</span> patches (<span class="math scholmd-math-inline">\(1100 \times 1100\)</span> pixels) for training and Figure <span class="scholmd-crossref"><a href="#Fig:inpainting-deblurring-evaluation">2</a></span> shows the results.</p>
<p>We compare our results with the solution of <span class="math scholmd-math-inline">\(\min \|\bx\|_\text{TV} \:\: \text{s.t.} \:\: \|B \bx - \bd_\text{obs} \|_2 \leq \sigma\)</span> (TV-BPDN), computed with the Matlab package TFOCS. We used TFOCS with a very small (TFOCS parameter <span class="math scholmd-math-inline">\(\mu=1e-5\)</span>) additional smoothing and ran the iterations until the solution signal to noise ratio (SNR) did not further improve. Additionally, we compare the results when we recover the wavelet coefficients, <span class="math scholmd-math-inline">\(\mathbf{c}\)</span>, by solving <span class="math scholmd-math-inline">\(\min \| \mathbf{c} \|_1 \:\: \text{s.t.} \:\: \|B W^* \mathbf{c} - \bd_\text{obs} \|_2 \leq \sigma\)</span> (TV-wavelet) with the SPGL1 toolbox for Matlab. The matrix <span class="math scholmd-math-inline">\(W\)</span> represents the wavelet transform. The learned set intersection approach achieves higher SNR for all evaluation images than the basis-pursuit denoise formulation tested with total-variation and with Wavelets (Daubechies wavelets as implemented by the SPOT linear operator toolbox (http://www.cs.ubc.ca/labs/scl/spot/index.html) and computed with the Rice Wavelet Toolbox (RWT, github.com/ricedsp/rwt)).</p>
<figure class="scholmd-float scholmd-figure" id="Fig:inpainting-deblurring-training">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/training_data_1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/training_data_2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/training_data_3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/training_data_4.png" />
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/training_data_5.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/training_data_6.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/training_data_7.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/training_data_8.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">1</span></span><span class="scholmd-caption-text">A sample of <span class="math scholmd-math-inline">\(8\)</span> out of <span class="math scholmd-math-inline">\(35\)</span> training images.</span></figcaption></div>
</figure>
<figure class="scholmd-float scholmd-figure" id="Fig:inpainting-deblurring-evaluation">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/deblurring_inpainting_observed1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/deblurring_inpainting_observed2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/deblurring_inpainting_observed3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/deblurring_inpainting_observed4.png" />
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/deblurring_inpainting_evaluation1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/deblurring_inpainting_evaluation2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/deblurring_inpainting_evaluation3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/deblurring_inpainting_evaluation4.png" />
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/PARSDMM_deblurring_inpainting1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/PARSDMM_deblurring_inpainting2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/PARSDMM_deblurring_inpainting3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/PARSDMM_deblurring_inpainting4.png" />
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/TFOCS_TV_inpainting1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/TFOCS_TV_inpainting2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/TFOCS_TV_inpainting3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/TFOCS_TV_inpainting4.png" />
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/SPGL1_wavelet_inpainting1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/SPGL1_wavelet_inpainting2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/SPGL1_wavelet_inpainting3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/inpainting_deblurring_figs/SPGL1_wavelet_inpainting4.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">2</span></span><span class="scholmd-caption-text">Reconstruction results from 80% missing pixels of an image with motion blur (25 pixels) and noise for PARSDMM with many learned constraints, BPDN-total-variation with TFOCS and BPDN-wavelet with SPGL1.</span></figcaption></div>
</figure>
<h2 id="example-2-image-desaturation">Example 2: Image desaturation</h2>
<p>We will now apply exactly the same strategy and algorithm to a different inverse problem. We only need to re-observe the constraint set parameters from a new set of training images (Figure <span class="scholmd-crossref"><a href="#Fig:deblurring-training">3</a></span>) and change our forward operator <span class="math scholmd-math-inline">\(B\)</span>. The second data set contains image patches from the ‘Desa Sangaji Kota Ternate’ image with a resolution of <span class="math scholmd-math-inline">\(11\)</span> centimeters and size of <span class="math scholmd-math-inline">\(1500 \times 1250\)</span> pixels, available at openaerialmap.org. (https://map.openaerialmap.org/#/-44.12109374999999,0,2/latest/5a17b890bac48e5b1c2f3b75?_k=4ag2c0). The observed images are saturated grayscale and generated by clipping the pixel values from <span class="math scholmd-math-inline">\(0 - 60\)</span> to <span class="math scholmd-math-inline">\(60\)</span> and from <span class="math scholmd-math-inline">\(125 - 255\)</span> to <span class="math scholmd-math-inline">\(125\)</span>. There is saturation on both the dark and bright pixels, but much stronger saturation on the high-intensity pixels than on the low-intensity ones. If we have no other information about the pixels at the clipped value, the desaturation problem implies the point-wise bound constraints 
<span class="math scholmd-math-display" style="display: block;">\[
\begin{equation}
\begin{cases}
0 \leq \bx_i \leq 60 &amp; \text{if } \bd^{\text{obs}}_i =60\\
\bx_i = \bd^{\text{obs}}_i &amp; \text{if } 60 \leq \bd^{\text{obs}}_i \leq 125\\
125 \leq \bx_i \leq 255 &amp; \text{if } \bd^{\text{obs}}_i = 125\\
\end{cases}.
\label{saturation_constraint}
\end{equation}
\]</span>
 The forward operator is thus the identity matrix, <span class="math scholmd-math-inline">\(B=I_N\)</span>. Other approaches also use this constraint for desaturation. We compare our results to a basis-pursuit denoise formulation that solves <span class="math scholmd-math-inline">\(\min_\bx \|A \bx\|_1 \:\: \text{s.t} \:\: \bl_i \leq \bx_i \leq \bu_i\)</span>, where <span class="math scholmd-math-inline">\(i\)</span> indexes the elements of the vectors and the bound constraints are as described above by Equation <span class="scholmd-crossref"><span class="math scholmd-math-inline">\(\eqref{saturation_constraint}\)</span></span>. The transform-domain matrix is the anisotropic total-variation operator. That work who also incorporates pre-processing and windowing techniques in the desaturation workflow for color images. We do not use any pre-processing and work with the full image.</p>
<figure class="scholmd-float scholmd-figure scholmd-widefloat" id="Fig:deblurring-training">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/training_data_1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/training_data_2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/training_data_3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/training_data_4.png" />
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/training_data_5.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/training_data_6.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/training_data_7.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/training_data_8.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">3</span></span><span class="scholmd-caption-text">A sample of <span class="math scholmd-math-inline">\(8\)</span> out of <span class="math scholmd-math-inline">\(16\)</span> training images.</span></figcaption></div>
</figure>
<p>Figure <span class="scholmd-crossref"><a href="#Fig:desaturation-evaluation">4</a></span> shows the results, true and observed data for four evaluation images. PARSDMM with learned parameters for preset constraints achieves a similar or slightly better SNR than minimization of the total-variation subject to a data-fit constraint. Both methods have problems with large saturated patches because there are no non-saturated observed pixels that serve as ‘anchor’ points. A difference between the BPDN and the projection onto intersection approach is how each method estimates large saturated patches. The TV-BPDN approach minimizes the total-variation, which means that the difference between the estimated pixel values of the saturated patches and the surrounding pixels needs to be as small as possible. The surrounding pixels are all <span class="math scholmd-math-inline">\(\leq 125\)</span>, so the estimated pixel values of large saturated patches are therefore also not exceeding <span class="math scholmd-math-inline">\(125\)</span>. The projection onto intersection approach does have this problem, because one of the constraints requires a sufficiently small total-variation that is based on a few representative training examples, instead of minimizing the total-variation. As we can see in Figure <span class="scholmd-crossref"><a href="#Fig:desaturation-evaluation">(4)</a></span>, the results from PARSDMM seem to recover better the intensity of large saturated patches (and sometimes overestimate) and have a better visual contrast than the BPDN results. Although the SNR does not clearly reveal this, the histograms of estimated pixel values show this effect. The projection onto a set intersection results are just one sample out of the feasible set. Different initial guesses may result in different projected points. We could compute multiple projections to obtain a sense of the estimation uncertainty.</p>
<figure class="scholmd-float scholmd-figure" id="Fig:desaturation-evaluation">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/desaturation_evaluation1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/desaturation_evaluation2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/desaturation_evaluation3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/desaturation_evaluation4.png" />
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/saturized_observed1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/saturized_observed2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/saturized_observed3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/saturized_observed4.png" />
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/PARSDMM_desaturation1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/PARSDMM_desaturation2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/PARSDMM_desaturation3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/PARSDMM_desaturation4.png" />
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/TV_BPDN_desaturation1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/TV_BPDN_desaturation2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/TV_BPDN_desaturation3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="images/desaturation_Ternate/TV_BPDN_desaturation4.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">4</span></span><span class="scholmd-caption-text">Reconstruction results from recovery from saturated images of PARSDMM with <span class="math scholmd-math-inline">\(10\)</span> constraints and BPDN-total-variation.</span></figcaption></div>
</figure>
<figure class="scholmd-float scholmd-figure" id="Fig:desaturation-histograms">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 25%">
<img src="images/desaturation_Ternate/hist_desaturation_PARSDMM1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 25%">
<img src="images/desaturation_Ternate/hist_desaturation_PARSDMM2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 25%">
<img src="images/desaturation_Ternate/hist_desaturation_PARSDMM3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 25%">
<img src="images/desaturation_Ternate/hist_desaturation_PARSDMM4.png" />
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: 25%">
<img src="images/desaturation_Ternate/hist_desaturation_TVBPDN1.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 25%">
<img src="images/desaturation_Ternate/hist_desaturation_TVBPDN2.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 25%">
<img src="images/desaturation_Ternate/hist_desaturation_TVBPDN3.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 25%">
<img src="images/desaturation_Ternate/hist_desaturation_TVBPDN4.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">5</span></span><span class="scholmd-caption-text">Histograms of reconstruction results from recovery from saturated images of PARSDMM with <span class="math scholmd-math-inline">\(10\)</span> constraints and BPDN-total-variation. The opaque (blue) histogram is the true image, the semi-transparant (brown) histogram corresponds to the recovered image.</span></figcaption></div>
</figure>
<p>Both examples show that PARSDMM with convex and non-convex sets converges to the desired feasibility tolerance and the results are similar or better than the basis-pursuit denoise formulation while the simple learning approach requires a few training examples only. It may be possible to improve the results from projection onto the set intersection by identifying the least similar training examples after the first reconstruction (e.g., removing images with clouds if it is clear that the reconstructed image has no clouds). The learned constraint parameters should then more accurately describe the image and may lead to improved reconstruction.</p>
<p></p>
<div class="references">

</div>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
      processClass: "math"
    },
    TeX: {
        TagSide: "left",
        TagIndent: "1.2em",
        equationNumbers: {
            autoNumber: "AMS"
        },
        Macros: {
            ensuremath: ["#1",1],
            textsf: ["\\mathsf{\\text{#1}}",1],
            texttt: ["\\mathtt{\\text{#1}}",1]
        }
    },
    "HTML-CSS": { 
        scale: 100,
        availableFonts: ["TeX"], 
        preferredFont: "TeX",
        webFont: "TeX",
        imageFont: "TeX",
        EqnChunk: 1000
    }
});
</script>
<script src="https://www.slim.eos.ubc.ca/Publications/Resources/ScholMD/js/slimweb-scholmd-scripts.js"></script>
<script src="https://www.slim.eos.ubc.ca/MathJax/MathJax.js?config=TeX-AMS_HTML-full" type="text/javascript"></script>
</div>
</body>
</html>
